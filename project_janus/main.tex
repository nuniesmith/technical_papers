\documentclass[12pt, a4paper]{article}

% --- PACKAGES ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{pmboxdraw}
\usepackage{newunicodechar}
\usepackage[english]{babel}
\usepackage{helvet}               % Helvetica for a clean, tech look
\renewcommand{\familydefault}{\sfdefault}
\usepackage{setspace}             % For line spacing
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{listings}             % For code snippets
\usepackage{tcolorbox}            % For highlighted boxes
\usepackage{tabularx}             % For auto-wrapping tables
\usepackage{array}                % For extra table column formatting

% --- Define Left-Aligned X Column for Tables ---
\newcolumntype{L}{>{\raggedright\arraybackslash}X}

% --- URL BREAKING ---
\usepackage{xurl}
\usepackage{hyperref}

% --- CONFIGURATION ---
\onehalfspacing                   % 1.5 Line Spacing for readability and length

% --- HEADER HEIGHT ---
\setlength{\headheight}{15pt}

\definecolor{janusblue}{RGB}{0, 51, 102}
\definecolor{accentgold}{RGB}{204, 153, 51}
\definecolor{warnred}{RGB}{153, 0, 0}

% --- UNICODE CHARACTER DECLARATIONS ---
\newunicodechar{▼}{\ensuremath{\blacktriangledown}}
\newunicodechar{→}{\ensuremath{\rightarrow}}
\newunicodechar{←}{\ensuremath{\leftarrow}}
\newunicodechar{↔}{\ensuremath{\leftrightarrow}}
\newunicodechar{⇒}{\ensuremath{\Rightarrow}}
\newunicodechar{…}{\ldots}
\newunicodechar{≥}{\ensuremath{\geq}}
\newunicodechar{≤}{\ensuremath{\leq}}
\newunicodechar{≠}{\ensuremath{\neq}}
\newunicodechar{≈}{\ensuremath{\approx}}
\newunicodechar{∈}{\ensuremath{\in}}
\newunicodechar{∉}{\ensuremath{\notin}}
\newunicodechar{∧}{\ensuremath{\wedge}}
\newunicodechar{∨}{\ensuremath{\vee}}
\newunicodechar{¬}{\ensuremath{\neg}}
\newunicodechar{×}{\ensuremath{\times}}
\newunicodechar{÷}{\ensuremath{\div}}
\newunicodechar{∞}{\ensuremath{\infty}}
\newunicodechar{∑}{\ensuremath{\sum}}
\newunicodechar{∏}{\ensuremath{\prod}}
\newunicodechar{∫}{\ensuremath{\int}}
\newunicodechar{√}{\ensuremath{\sqrt}}
\newunicodechar{∂}{\ensuremath{\partial}}
\newunicodechar{∇}{\ensuremath{\nabla}}
\newunicodechar{α}{\ensuremath{\alpha}}
\newunicodechar{β}{\ensuremath{\beta}}
\newunicodechar{γ}{\ensuremath{\gamma}}
\newunicodechar{δ}{\ensuremath{\delta}}
\newunicodechar{ε}{\ensuremath{\epsilon}}
\newunicodechar{θ}{\ensuremath{\theta}}
\newunicodechar{λ}{\ensuremath{\lambda}}
\newunicodechar{μ}{\ensuremath{\mu}}
\newunicodechar{π}{\ensuremath{\pi}}
\newunicodechar{σ}{\ensuremath{\sigma}}
\newunicodechar{τ}{\ensuremath{\tau}}
\newunicodechar{φ}{\ensuremath{\phi}}
\newunicodechar{ω}{\ensuremath{\omega}}
\newunicodechar{Δ}{\ensuremath{\Delta}}
\newunicodechar{Σ}{\ensuremath{\Sigma}}
\newunicodechar{Π}{\ensuremath{\Pi}}
\newunicodechar{Ω}{\ensuremath{\Omega}}

\hypersetup{
    colorlinks=true,
    linkcolor=janusblue,
    citecolor=janusblue,
    urlcolor=accentgold,
    pdftitle={Project JANUS: Neuromorphic Trading Intelligence},
    pdfauthor={Jordan Smith}
}

% --- HEADER & FOOTER ---
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\textbf{Project JANUS}}
\fancyhead[R]{\textit{Main Architecture Overview}}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0pt}

% --- SECTION STYLING ---
\titleformat{\section}
  {\color{janusblue}\normalfont\Large\bfseries}
  {\thesection}{1em}{}
\titleformat{\subsection}
  {\color{janusblue}\normalfont\large\bfseries}
  {\thesubsection}{1em}{}

% --- CODE SNIPPET STYLE ---
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    keywordstyle=\color{blue},
    commentstyle=\color{green!50!black},
    stringstyle=\color{red}
}

% --- DOCUMENT START ---
\begin{document}

% =============================================================================
% TITLE PAGE
% =============================================================================
\begin{titlepage}
    \pagenumbering{gobble}
    \centering
    \vspace*{2cm}

    {\Huge \textbf{Project JANUS}} \\[0.5cm]
    {\LARGE \textbf{Neuromorphic Trading Intelligence}} \\[1cm]

    {\Large \textit{A Brain-Inspired Architecture for Autonomous Financial Systems}} \\[2.5cm]

    \begin{tcolorbox}[colback=gray!10, colframe=janusblue, width=0.85\textwidth, arc=3mm, boxrule=0.5mm]
        \centering
        \textbf{\large The Two-Faced Architecture}\\[0.3cm]
        \textit{Forward (Janus Bifrons): The Conscious Trader}\\
        Visual perception, logical reasoning, and real-time execution\\[0.3cm]
        \textit{Backward (Janus Consivius): The Sleeping Mind}\\
        Memory consolidation, schema formation, and learning
    \end{tcolorbox}

    \vspace{1.5cm}

    \textbf{\Large Classification: Main Architecture Document} \\[0.5cm]
    \textbf{\Large Version: 2.0} \\[2cm]

    \textbf{Author:} Jordan Smith \\
    \textit{github.com/nuniesmith} \\[0.5cm]
    \textbf{Date:} \today

    \vfill

    \textit{``The god of beginnings and transitions, looking simultaneously to the future and the past.''}
\end{titlepage}

% =============================================================================
% ABSTRACT
% =============================================================================
\newpage
\pagenumbering{arabic}
\thispagestyle{plain}
\section*{Abstract}

Financial markets have evolved into complex adaptive systems operating at timescales far beyond human perception. Modern high-frequency trading requires decision-making in microseconds, processing millions of data points across multiple modalities—price movements, order flow toxicity, news sentiment, and macroeconomic signals—while adhering to strict regulatory and risk management constraints. The challenge is not merely computational speed, but the integration of \textit{perception}, \textit{reasoning}, and \textit{memory} into a unified autonomous system.

This document presents \textbf{Project JANUS}, a neuromorphic trading intelligence system inspired by the bifurcated nature of its namesake—the Roman god who simultaneously looks forward and backward. JANUS represents a paradigm shift from monolithic deep learning models to a brain-inspired architecture that mirrors the functional specialization and information flow patterns observed in biological neural systems.

The architecture is fundamentally dual:

\begin{itemize}[leftmargin=*]
    \item \textbf{JANUS Forward (Janus Bifrons)}: The ``wake state'' trading engine that operates in real-time market conditions. It implements visual pattern recognition through Gramian Angular Fields (GAF) and Video Vision Transformers (ViViT), symbolic reasoning through Logic Tensor Networks (LTN), multimodal fusion via gated cross-attention, and neuromorphic decision-making inspired by basal ganglia dual pathways.

    \item \textbf{JANUS Backward (Janus Consivius)}: The ``sleep state'' memory consolidation system that processes trading experiences during off-market hours. It implements a three-timescale memory hierarchy (hippocampal episodic buffer, sharp-wave ripple replay, and neocortical schema formation), UMAP-based cognitive visualization, and integration with vector databases for long-term knowledge storage.
\end{itemize}

By separating the hot-path real-time inference (Forward) from the cold-path batch learning (Backward), JANUS achieves both microsecond-latency execution and deep, contemplative learning—mirroring the wake-sleep cycle of biological brains. The system is implemented in Rust for performance-critical components and Python for training pipelines, with explicit neuromorphic mapping to brain regions: visual cortex, prefrontal cortex, hippocampus, basal ganglia, thalamus, amygdala, hypothalamus, cerebellum, and integration centers.

This main document provides the conceptual framework, architectural philosophy, and system integration overview. Detailed technical specifications are provided in companion documents:
\begin{itemize}
    \item \texttt{janus\_forward.tex} — Forward service algorithms and implementation
    \item \texttt{janus\_backward.tex} — Backward service memory architecture
    \item \texttt{janus\_neuromorphic\_architecture.tex} — Brain region mapping and neuromorphic design
    \item \texttt{janus\_rust\_implementation.tex} — Rust implementation strategy and deployment
\end{itemize}

\textbf{Key Contributions:}
\begin{enumerate}
    \item A neuromorphic architecture that maps trading functions to specialized brain regions
    \item Differentiable Gramian Angular Fields (DiffGAF) for learnable time series imaging
    \item Logic Tensor Networks for hard constraint enforcement in financial decision-making
    \item Sharp-wave ripple simulation for experience replay with 10-20× time compression
    \item Dual-service architecture separating real-time inference from batch consolidation
    \item Rust-first implementation for safety-critical financial systems
\end{enumerate}

\newpage
% =============================================================================
% TABLE OF CONTENTS
% =============================================================================
\tableofcontents
\newpage

% =============================================================================
% INTRODUCTION
% =============================================================================
\section{Introduction: The Crisis of Complexity}

\subsection{The Evolution of Quantitative Trading}

The history of quantitative trading can be characterized by escalating complexity and decreasing human interpretability:

\begin{itemize}
    \item \textbf{Quant 1.0 (1970s-1990s):} Rule-based expert systems and technical indicators (moving averages, RSI, Bollinger Bands). Human-interpretable but brittle and unable to capture complex non-linear dynamics.

    \item \textbf{Quant 2.0 (1990s-2010s):} Statistical arbitrage and factor models (ARIMA, GARCH, Fama-French factors). Economically grounded but limited by linear assumptions and Gaussian priors.

    \item \textbf{Quant 3.0 (2010s-2020s):} Deep learning and end-to-end optimization (LSTMs, Transformers, Deep RL). Powerful pattern recognition but opaque reasoning, regulatory risks, and catastrophic failures during regime shifts.

    \item \textbf{Quant 4.0 (2020s-present):} Neuro-symbolic systems combining neural perception with symbolic reasoning. The integration of vision-based pattern recognition, logical constraint satisfaction, and hierarchical decision-making.
\end{itemize}

Project JANUS represents a realization of the Quant 4.0 vision, moving beyond pure deep learning toward hybrid systems that combine the intuitive power of neural networks with the logical rigor of symbolic AI and the biological plausibility of neuromorphic architectures.

\subsection{The Black Box Crisis}

Modern deep reinforcement learning agents can achieve superhuman performance on complex tasks, but this performance comes at a cost: \textit{opacity}. A DRL agent trained solely to maximize Sharpe ratio may discover strategies that:

\begin{itemize}
    \item Exploit simulator artifacts that don't exist in live markets (reality gap)
    \item Violate regulatory constraints (wash sales, market manipulation, front-running)
    \item Fail catastrophically during regime shifts unseen in training data
    \item Exhibit emergent behaviors that are impossible to audit or explain
\end{itemize}

In traditional software engineering, this would be unacceptable. Financial systems require:

\begin{enumerate}
    \item \textbf{Explainability:} Every trading decision must be auditable and defensible
    \item \textbf{Safety:} Hard constraints (risk limits, regulatory rules) must be enforced
    \item \textbf{Robustness:} Systems must degrade gracefully under extreme market conditions
    \item \textbf{Adaptability:} Systems must learn from experience without catastrophic forgetting
\end{enumerate}

The challenge is to build systems that achieve these properties while maintaining the pattern recognition power of modern deep learning.

\subsection{The Neuromorphic Solution}

Biological brains solve many of the same challenges faced by autonomous trading systems:

\begin{itemize}
    \item \textbf{Real-time processing:} Sensory-motor loops operate in milliseconds
    \item \textbf{Multi-timescale learning:} Immediate reactions (reflexes), medium-term adaptation (skill learning), long-term consolidation (memory)
    \item \textbf{Constraint satisfaction:} Motor commands must respect physical constraints (joint limits, balance)
    \item \textbf{Homeostasis:} Internal states (hunger, stress) must be regulated
    \item \textbf{Memory consolidation:} Experiences are replayed and abstracted during sleep
\end{itemize}

By mapping trading functions to brain regions with analogous roles, JANUS creates a system that is both neuroscientifically inspired and functionally specialized:

\begin{table}[h!]
\centering
\begin{tabularx}{\textwidth}{|l|L|L|}
\hline
\textbf{Brain Region} & \textbf{Neuroscience Role} & \textbf{Trading Role} \\
\hline
Visual Cortex & Pattern recognition in images & GAF/ViViT market pattern detection \\
\hline
Prefrontal Cortex & Logic, planning, rule adherence & LTN constraint enforcement \\
\hline
Hippocampus & Episodic memory, replay & Experience buffer, SWR simulation \\
\hline
Neocortex & Long-term schemas & Consolidated strategies, vector DB \\
\hline
Basal Ganglia & Action selection, Go/No-Go & Dual-pathway decision engine \\
\hline
Cerebellum & Motor control, prediction & Order execution, market impact model \\
\hline
Thalamus & Attention, multimodal fusion & Gated cross-attention fusion \\
\hline
Amygdala & Fear, threat detection & Circuit breakers, risk alerts \\
\hline
Hypothalamus & Homeostasis, drive states & Risk appetite, position sizing \\
\hline
\end{tabularx}
\caption{Neuromorphic Mapping: Brain Regions to Trading Functions}
\end{table}

This mapping is not merely metaphorical—it guides the architectural design, data flow, and optimization strategies throughout the system.

\newpage
% =============================================================================
% ARCHITECTURAL PHILOSOPHY
% =============================================================================
\section{Architectural Philosophy: The Two Faces of JANUS}

\subsection{Why Dual Architecture?}

The central insight of Project JANUS is that \textit{real-time decision-making} and \textit{reflective learning} are fundamentally different computational regimes that should be decoupled:

\begin{itemize}
    \item \textbf{Forward (Wake State):} Operates during market hours under extreme latency constraints (microseconds to milliseconds). Must process streaming data, fuse multimodal inputs, evaluate logical constraints, and execute trades—all while maintaining deterministic worst-case performance.

    \item \textbf{Backward (Sleep State):} Operates during off-market hours without latency constraints. Can perform computationally expensive operations: prioritized experience replay, UMAP dimensionality reduction, schema clustering, vector database consolidation, and model retraining.
\end{itemize}

This separation mirrors the biological wake-sleep cycle, where:
\begin{itemize}
    \item During wakefulness, the brain prioritizes fast sensory-motor integration
    \item During sleep, the brain replays experiences (sharp-wave ripples in hippocampus), consolidates memories to neocortex, and prunes synapses
\end{itemize}

\subsection{Janus Bifrons: The Forward Face}

\textbf{Janus Bifrons} (``two-faced'') represents the conscious, awake trader. The Forward service implements:

\begin{enumerate}
    \item \textbf{Visual Pattern Recognition:}
    \begin{itemize}
        \item Differentiable Gramian Angular Fields (DiffGAF) transform 1D time series into 2D images with learnable normalization
        \item GAF Video sequences capture spatiotemporal market evolution
        \item Video Vision Transformer (ViViT) processes multi-frame sequences with factorized spatial-temporal attention
        \item Limit Order Book (LOB) heatmap fusion for microstructure awareness
    \end{itemize}

    \item \textbf{Symbolic Reasoning:}
    \begin{itemize}
        \item Logic Tensor Networks (LTN) embed regulatory and risk constraints as differentiable logical predicates
        \item Lukasiewicz T-Norm operations (AND, OR, NOT, IMPLIES, FORALL, EXISTS) enable gradient-based satisfaction
        \item Knowledge base includes wash sale rules, Almgren-Chriss risk constraints, and VPIN toxicity thresholds
    \end{itemize}

    \item \textbf{Multimodal Fusion:}
    \begin{itemize}
        \item Gated Cross-Attention fuses visual embeddings (ViViT), time series forecasts (Chronos-Bolt), and text embeddings (FinBERT)
        \item Learnable gating weights determine modality importance dynamically
    \end{itemize}

    \item \textbf{Neuromorphic Decision Engine:}
    \begin{itemize}
        \item Basal ganglia-inspired dual pathways: Direct (Go) and Indirect (No-Go)
        \item Cerebellar forward model predicts market impact and execution cost
        \item Action is authorized only when Go > No-Go and LTN constraints are satisfied
    \end{itemize}
\end{enumerate}

\subsection{Janus Consivius: The Backward Face}

\textbf{Janus Consivius} (``sower'', ``planter'') represents the reflective, consolidating mind. The Backward service implements:

\begin{enumerate}
    \item \textbf{Three-Timescale Memory Hierarchy:}
    \begin{itemize}
        \item \textit{Short-term (Hippocampus):} Episodic buffer stores raw experiences with pattern separation and sparse encoding
        \item \textit{Medium-term (SWR):} Sharp-wave ripple simulation replays high-priority experiences with 10-20× time compression
        \item \textit{Long-term (Neocortex):} Schema formation via clustering and consolidation to vector database (Qdrant)
    \end{itemize}

    \item \textbf{Prioritized Replay:}
    \begin{itemize}
        \item Experiences prioritized by TD-error, LTN violation severity, and recency
        \item SumTree data structure for $O(\log N)$ sampling
        \item Importance sampling correction to prevent bias
    \end{itemize}

    \item \textbf{Cognitive Visualization:}
    \begin{itemize}
        \item AlignedUMAP projects experiences across training epochs to detect schema formation
        \item Parametric UMAP enables real-time anomaly detection and regime shift visualization
    \end{itemize}

    \item \textbf{Vector Database Integration:}
    \begin{itemize}
        \item Qdrant stores consolidated schemas as high-dimensional embeddings
        \item Similarity search retrieves relevant past experiences for few-shot adaptation
        \item Periodic pruning removes outdated or redundant schemas
    \end{itemize}
\end{enumerate}

\subsection{Information Flow Between Services}

The Forward and Backward services communicate asynchronously:

\begin{enumerate}
    \item \textbf{During Market Hours (Forward Active):}
    \begin{itemize}
        \item Forward service processes live market data and executes trades
        \item Experiences (state, action, reward, next state, LTN violations) are written to shared episodic buffer
        \item No blocking—buffer writes are lock-free and wait-free
    \end{itemize}

    \item \textbf{During Off-Hours (Backward Active):}
    \begin{itemize}
        \item Backward service consumes episodic buffer
        \item Prioritized replay generates training batches
        \item SWR simulation compresses experiences
        \item Schemas are consolidated to Qdrant
        \item Updated model weights are exported (ONNX) and versioned
    \end{itemize}

    \item \textbf{Model Deployment:}
    \begin{itemize}
        \item Forward service loads new ONNX models during market close
        \item Shadow deployment allows parallel evaluation before promotion
        \item Graceful fallback to previous model if validation fails
    \end{itemize}
\end{enumerate}

\newpage
% =============================================================================
% CORE COMPONENTS
% =============================================================================
\section{Core Components: Hybrid Intelligence}

\subsection{Vision: Seeing the Market's Geometry}

\subsubsection{Why Visual Encoding?}

Financial time series are traditionally represented as 1D sequences of scalars. This representation is efficient for storage but discards the rich topological structure of market dynamics. By transforming time series into images, we unlock the architectural power of Computer Vision:

\begin{itemize}
    \item \textbf{Convolutional layers} detect hierarchical spatial patterns (edges, textures, shapes)
    \item \textbf{Translation invariance} recognizes patterns regardless of position
    \item \textbf{Attention mechanisms} focus on salient regions
\end{itemize}

In the context of transformed time series, these visual patterns correspond to:
\begin{itemize}
    \item \textit{Edges} → Regime transitions (trend reversals, volatility shifts)
    \item \textit{Textures} → Microstructure patterns (volatility clustering, mean reversion)
    \item \textit{Shapes} → Macrostructure formations (head-and-shoulders, flags, triangles)
\end{itemize}

\subsubsection{Differentiable Gramian Angular Fields (DiffGAF)}

JANUS introduces \textbf{DiffGAF}, a learnable variant of Gramian Angular Fields that enables end-to-end gradient flow from the visual classifier back through the imaging transformation.

Given a time series $X = \{x_1, x_2, \ldots, x_n\}$:

\textbf{Step 1: Learnable Normalization}
\begin{equation}
    \tilde{x}_i = \tanh\left(\frac{x_i - \min(X)}{\max(X) - \min(X)} \cdot \alpha + \beta\right)
\end{equation}

where $\alpha, \beta$ are learnable parameters optimized during training.

\textbf{Step 2: Polar Encoding}
\begin{equation}
\begin{cases}
\phi_i = \arccos(\tilde{x}_i), & -1 \le \tilde{x}_i \le 1 \\
r_i = \frac{t_i}{N}, & t_i \in \mathbb{N}
\end{cases}
\end{equation}

\textbf{Step 3: Gramian Field Generation}

Gramian Angular Summation Field (GASF):
\begin{equation}
    \text{GASF}_{i,j} = \cos(\phi_i + \phi_j)
\end{equation}

Gramian Angular Difference Field (GADF):
\begin{equation}
    \text{GADF}_{i,j} = \sin(\phi_i - \phi_j)
\end{equation}

The resulting $n \times n$ image preserves temporal correlation structure while enabling spatial convolution.

\subsubsection{GAF Video and ViViT}

Static images capture instantaneous market state. To capture \textit{evolution}, JANUS generates GAF video sequences using sliding windows:

\begin{equation}
    \mathcal{V} = \{GAF(X_{t:t+w}), GAF(X_{t+s:t+w+s}), \ldots\}
\end{equation}

where $w$ is window size and $s$ is stride. The resulting 3D tensor $\mathcal{V} \in \mathbb{R}^{F \times H \times W}$ is processed by a Video Vision Transformer (ViViT) with:

\begin{itemize}
    \item \textbf{Spatial attention} within each frame (volatility clusters, trend structures)
    \item \textbf{Temporal attention} across frames (regime transitions, momentum shifts)
\end{itemize}

\subsection{Logic: Enforcing the Rules of the Game}

\subsubsection{The Necessity of Symbolic Constraints}

Deep learning excels at pattern recognition but lacks logical precision. In finance, ``close enough'' is unacceptable:

\begin{itemize}
    \item A wash sale (selling at a loss and repurchasing within 30 days) triggers tax penalties
    \item Exceeding risk limits violates Almgren-Chriss constraints and regulatory mandates
    \item Order flow toxicity (high VPIN) indicates informed trading and adverse selection risk
\end{itemize}

These are not soft preferences—they are \textit{hard constraints} that must be satisfied with mathematical certainty.

\subsubsection{Logic Tensor Networks (LTN)}

LTN embeds First-Order Logic (FOL) into neural networks by grounding logical symbols in continuous tensor space:

\begin{itemize}
    \item \textbf{Constants} → Tensor embeddings
    \item \textbf{Predicates} → Neural networks outputting $[0,1]$ truth values
    \item \textbf{Logical connectives} → Fuzzy logic t-norms
\end{itemize}

JANUS uses Lukasiewicz t-norms for improved gradient flow:

\begin{align}
    \text{AND}(p, q) &= \max(0, p + q - 1) \\
    \text{OR}(p, q) &= \min(1, p + q) \\
    \text{NOT}(p) &= 1 - p \\
    \text{IMPLIES}(p, q) &= \min(1, 1 - p + q)
\end{align}

\subsubsection{Knowledge Base Examples}

\textbf{Wash Sale Constraint:}
\begin{equation}
    \forall t: \text{Sold}(t) \land \text{Loss}(t) \implies \neg \text{Buy}(t, t+30)
\end{equation}

``If a position was sold at a loss, do not repurchase within 30 days.''

\textbf{Almgren-Chriss Risk Constraint:}
\begin{equation}
    \forall \tau: \text{Variance}(\tau) \le \lambda \cdot \text{MarketImpact}(\tau)
\end{equation}

``Execution variance must not exceed risk tolerance.''

\textbf{VPIN Toxicity Constraint:}
\begin{equation}
    \text{VPIN}(t) > \theta \implies \text{Widen}(\text{spread}) \lor \text{Halt}(\text{trading})
\end{equation}

``If order flow toxicity exceeds threshold, widen spreads or halt.''

\subsection{Fusion: Integrating Multiple Realities}

\subsubsection{The Multimodal Challenge}

Markets are inherently multimodal. A complete understanding requires:

\begin{itemize}
    \item \textbf{Visual patterns} (GAF video, LOB heatmaps)
    \item \textbf{Time series forecasts} (Chronos-Bolt probabilistic predictions)
    \item \textbf{Text semantics} (news, earnings calls, social media)
    \item \textbf{Logical constraints} (LTN predicate evaluations)
\end{itemize}

The challenge is not merely concatenating these modalities but learning their relative importance dynamically.

\subsubsection{Gated Cross-Attention (GCA)}

JANUS uses GCA to fuse modalities with learnable gating:

\begin{align}
    \text{Attention}(Q, K, V) &= \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right) V \\
    g &= \sigma(W_g \cdot [x_{\text{visual}}; x_{\text{time}}; x_{\text{text}}] + b_g) \\
    x_{\text{fused}} &= g \odot \text{Attention}(x_{\text{visual}}, x_{\text{time}}, x_{\text{time}})
\end{align}

The gating weight $g \in [0, 1]$ determines how much to trust each modality. During high volatility, visual patterns may dominate; during earnings season, text embeddings may be prioritized.

\subsection{Decision: The Neuromorphic Motor System}

\subsubsection{Basal Ganglia Dual Pathways}

The basal ganglia implements action selection via competing pathways:

\begin{itemize}
    \item \textbf{Direct Pathway (Go):} Facilitates action execution
    \item \textbf{Indirect Pathway (No-Go):} Inhibits action execution
\end{itemize}

JANUS mirrors this with dual neural networks:

\begin{align}
    \text{Go}(s) &= f_{\text{direct}}(s; \theta_{\text{Go}}) \\
    \text{NoGo}(s) &= f_{\text{indirect}}(s; \theta_{\text{NoGo}}) \\
    a &= \begin{cases}
        a_{\text{proposed}} & \text{if } \text{Go}(s) > \text{NoGo}(s) \land \text{LTN}(s, a) > \tau \\
        \text{HOLD} & \text{otherwise}
    \end{cases}
\end{align}

This architecture naturally implements risk-averse behavior: actions are blocked unless both pathways agree AND logical constraints are satisfied.

\subsubsection{Cerebellar Forward Model}

The cerebellum predicts sensory consequences of motor commands. JANUS implements a market impact predictor:

\begin{equation}
    \hat{p}_{\text{fill}} = f_{\text{cerebellum}}(a, s_{\text{LOB}})
\end{equation}

This prediction enables:
\begin{itemize}
    \item \textbf{Trajectory adjustment:} Modify order size/timing to minimize slippage
    \item \textbf{Error correction:} Compare predicted vs. actual fill price and update model
\end{itemize}

\newpage
% =============================================================================
% MEMORY AND LEARNING
% =============================================================================
\section{Memory and Learning: The Sleeping Mind}

\subsection{The Three-Timescale Hierarchy}

Biological memory systems operate at multiple timescales:

\begin{itemize}
    \item \textbf{Hippocampus:} Rapid encoding of episodic details (seconds to hours)
    \item \textbf{Sharp-Wave Ripples:} Replay and consolidation during rest (minutes to hours)
    \item \textbf{Neocortex:} Long-term schemas and abstract knowledge (days to years)
\end{itemize}

JANUS replicates this hierarchy:

\subsubsection{Short-Term: Hippocampal Episodic Buffer}

Raw experiences are stored with minimal processing:

\begin{equation}
    e_t = (s_t, a_t, r_t, s_{t+1}, \text{done}_t, \text{LTN}_t, \text{meta}_t)
\end{equation}

where $\text{LTN}_t$ records constraint violations and $\text{meta}_t$ includes timestamps, market regime labels, etc.

\textbf{Pattern separation} ensures diverse storage:
\begin{equation}
    \text{similarity}(e_i, e_j) < \tau_{\text{sep}} \implies \text{store both}
\end{equation}

\subsubsection{Medium-Term: Sharp-Wave Ripple (SWR) Simulation}

During sleep, the hippocampus replays experiences at 10-20× real-time speed. JANUS simulates this with:

\begin{enumerate}
    \item \textbf{Prioritized sampling:} Select high TD-error, high LTN-violation experiences
    \item \textbf{Time compression:} Process entire trading day in 10-30 minutes
    \item \textbf{Batch generation:} Create training batches for model updates
\end{enumerate}

Priority weighting:
\begin{equation}
    p_i = (|\delta_i| + \epsilon)^\alpha + \beta \cdot \text{LTN\_violation}_i + \gamma \cdot \text{recency}_i
\end{equation}

\subsubsection{Long-Term: Neocortical Schemas}

Repeated experiences are abstracted into schemas—general patterns that transcend specific episodes:

\begin{equation}
    \theta_{\text{schema}} \leftarrow \theta_{\text{schema}} + \eta \cdot \text{recall\_gate} \cdot \nabla_\theta \mathcal{L}
\end{equation}

Recall gating prevents interference:
\begin{equation}
    \text{recall\_gate} = \mathbb{1}[\text{cosine\_similarity}(e_{\text{current}}, \text{schema}) > \tau_{\text{recall}}]
\end{equation}

Only experiences similar to existing schemas contribute to consolidation, reducing catastrophic forgetting.

\subsection{Cognitive Visualization: UMAP}

\subsubsection{AlignedUMAP for Schema Detection}

During training, experiences are projected to 2D space across epochs:

\begin{equation}
    \mathcal{L}_{\text{UMAP}} = \sum_{i,j} w_{ij} \log\left(\frac{1}{1 + \|y_i - y_j\|^2}\right) + (1 - w_{ij})\log\left(1 - \frac{1}{1 + \|y_i - y_j\|^2}\right)
\end{equation}

Cluster formation in UMAP space indicates emerging schemas. Cluster stability across epochs validates consolidation.

\subsubsection{Parametric UMAP for Anomaly Detection}

A neural network learns the UMAP projection:

\begin{equation}
    y = f_{\text{UMAP}}(x; \theta)
\end{equation}

At inference time, new experiences are projected in real-time. Outliers indicate:
\begin{itemize}
    \item Regime shifts (market structure change)
    \item Novel strategies (unexplored state space)
    \item Data quality issues (sensor failures)
\end{itemize}

\newpage
% =============================================================================
% IMPLEMENTATION STRATEGY
% =============================================================================
\section{Implementation Strategy: Rust-First Architecture}

\subsection{Why Rust?}

Financial systems demand:

\begin{itemize}
    \item \textbf{Performance:} Microsecond latencies, zero-copy operations
    \item \textbf{Safety:} No null pointers, no data races, no undefined behavior
    \item \textbf{Reliability:} Predictable performance, deterministic memory usage
    \item \textbf{Auditability:} Strong type system, explicit error handling
\end{itemize}

Rust provides all of these without garbage collection pauses or runtime overhead.

\subsection{Service Architecture}

JANUS is implemented as two Rust services with a Python training gateway:

\begin{enumerate}
    \item \textbf{Forward Service (Rust):}
    \begin{itemize}
        \item Async runtime (Tokio) for concurrent market data streams
        \item ONNX Runtime for model inference (ViViT, LTN predicates)
        \item Lock-free queues for experience buffer writes
        \item gRPC API for order submission
    \end{itemize}

    \item \textbf{Backward Service (Rust):}
    \begin{itemize}
        \item Rayon for parallel batch processing
        \item SumTree (custom implementation) for prioritized replay
        \item Qdrant client for vector database operations
        \item UMAP projection (via ONNX or direct Rust port)
    \end{itemize}

    \item \textbf{Training Gateway (Python):}
    \begin{itemize}
        \item PyTorch for model training
        \item FastAPI for REST endpoints
        \item Celery for async batch jobs (SWR simulation, model export)
        \item Model export to ONNX for Rust consumption
    \end{itemize}
\end{enumerate}

\subsection{ML Framework Migration Path}

\begin{enumerate}
    \item \textbf{Phase 1 (Months 1-3):} Hybrid PyTorch + ONNX
    \begin{itemize}
        \item Train in PyTorch, export to ONNX, infer in Rust
        \item Establish benchmarks and validation pipelines
    \end{itemize}

    \item \textbf{Phase 2 (Months 4-6):} Rust-native inference
    \begin{itemize}
        \item Port inference to tch-rs (libtorch) or Candle
        \item Eliminate Python dependency for deployment
    \end{itemize}

    \item \textbf{Phase 3 (Months 7-12):} Full Rust ML stack
    \begin{itemize}
        \item Port training to Burn or Candle
        \item Single-language codebase for maximum auditability
    \end{itemize}
\end{enumerate}

\subsection{Deployment Architecture}

\textbf{Development:}
\begin{itemize}
    \item Docker Compose for local multi-service orchestration
    \item Shared volumes for model artifacts and experience buffers
    \item PostgreSQL for metadata, Qdrant for vectors, Redis for pub/sub
\end{itemize}

\textbf{Production:}
\begin{itemize}
    \item Kubernetes for orchestration and auto-scaling
    \item StatefulSets for Qdrant and PostgreSQL
    \item Helm charts for versioned deployments
    \item Prometheus + Grafana for monitoring
    \item Shadow deployment for A/B testing
\end{itemize}

\newpage
% =============================================================================
% SAFETY AND COMPLIANCE
% =============================================================================
\section{Safety and Compliance: The Glass Box}

\subsection{Architectural Invariants}

JANUS enforces architectural invariants through Rust's type system:

\begin{enumerate}
    \item \textbf{No Panics in Hot Path:}
    \begin{itemize}
        \item All errors are typed (using \texttt{thiserror})
        \item \texttt{unwrap()} and \texttt{expect()} forbidden in production code
        \item Fallback strategies for all error conditions
    \end{itemize}

    \item \textbf{LTN Constraints Always Evaluated:}
    \begin{itemize}
        \item Actions cannot be executed without LTN evaluation
        \item Constraint violations logged and traced
        \item Circuit breakers halt trading on repeated violations
    \end{itemize}

    \item \textbf{Memory Bounds Enforced:}
    \begin{itemize}
        \item Episodic buffer has maximum size with FIFO eviction
        \item No unbounded allocations in hot path
        \item Pre-allocated buffers for latency-critical operations
    \end{itemize}

    \item \textbf{Temporal Guarantees:}
    \begin{itemize}
        \item SWR compression factor $\in [10, 20]$ verified at runtime
        \item Replay cannot exceed configured wall-clock time
        \item Timeout guards on all external API calls
    \end{itemize}
\end{enumerate}

\subsection{Explainability and Auditability}

Every trading decision generates an audit trail:

\begin{enumerate}
    \item \textbf{Visual Attention:} Grad-CAM heatmaps show which GAF frames influenced the decision
    \item \textbf{Logical Trace:} LTN evaluations are logged with predicate truth values
    \item \textbf{Modality Weights:} GCA gating values indicate which inputs were trusted
    \item \textbf{Pathway Activation:} Go/No-Go scores explain action selection
    \item \textbf{Forward Model Error:} Predicted vs. actual slippage quantifies model confidence
\end{enumerate}

This trace is stored in structured logs (JSON) and indexed for regulatory queries.

\subsection{Circuit Breakers and Kill Switches}

The \textbf{Amygdala} subsystem implements safety-critical overrides:

\begin{enumerate}
    \item \textbf{Volatility Spike:} Halt trading if realized volatility $> 3 \times$ historical
    \item \textbf{Drawdown Limit:} Halt if portfolio drawdown $> 10\%$ in single session
    \item \textbf{LTN Violation Rate:} Halt if $> 5\%$ of actions violate constraints
    \item \textbf{Execution Anomaly:} Halt if average slippage $> 2 \times$ predicted
    \item \textbf{Manual Override:} Human operators can trigger emergency halt via API
\end{enumerate}

All circuit breakers are \textit{fail-safe}: they default to halting trading on error or uncertainty.

\newpage
% =============================================================================
% VALIDATION AND TESTING
% =============================================================================
\section{Validation and Testing: Proving Robustness}

\subsection{Simulation and Backtesting}

JANUS is validated through progressive realism:

\begin{enumerate}
    \item \textbf{Unit Tests:} Each component tested in isolation
    \begin{itemize}
        \item GAF transformation invertibility
        \item LTN predicate gradient flow
        \item SumTree priority sampling correctness
    \end{itemize}

    \item \textbf{Synthetic Markets:} Controlled environments with known properties
    \begin{itemize}
        \item Mean-reverting Ornstein-Uhlenbeck process
        \item Momentum-driven geometric Brownian motion
        \item Regime-switching models with abrupt transitions
    \end{itemize}

    \item \textbf{Historical Replay:} Real market data with simulated execution
    \begin{itemize}
        \item Out-of-sample testing on unseen time periods
        \item Walk-forward optimization to prevent overfitting
        \item Comparison with baseline strategies (buy-and-hold, momentum, mean-reversion)
    \end{itemize}

    \item \textbf{Black Swan Stress Tests:} Extreme scenarios
    \begin{itemize}
        \item Flash crash (May 6, 2010)
        \item COVID crash (March 2020)
        \item GameStop short squeeze (January 2021)
    \end{itemize}

    \item \textbf{Paper Trading:} Live market data with simulated execution
    \begin{itemize}
        \item Reality gap monitoring (predicted vs. actual slippage)
        \item Latency profiling under production load
    \end{itemize}

    \item \textbf{Shadow Deployment:} Parallel execution with production system
    \begin{itemize}
        \item JANUS generates signals but does not execute
        \item Performance compared with existing live system
        \item Gradual rollout (1\% → 10\% → 50\% → 100\%)
    \end{itemize}
\end{enumerate}

\subsection{Comparative Benchmarks}

JANUS is compared against:

\begin{itemize}
    \item \textbf{Baseline:} Buy-and-hold, equal-weight portfolio
    \item \textbf{Traditional Quant:} ARIMA, GARCH, Fama-French factors
    \item \textbf{Deep Learning:} LSTM, Transformer, pure DRL (PPO, SAC)
    \item \textbf{Neuro-Symbolic (No Vision):} LTN + time series only
    \item \textbf{Vision-Only (No Logic):} ViViT without LTN constraints
\end{itemize}

Metrics evaluated:
\begin{itemize}
    \item Sharpe Ratio, Sortino Ratio, Calmar Ratio
    \item Maximum Drawdown, Value-at-Risk (VaR), Conditional VaR
    \item Trade execution quality (average slippage, fill rate)
    \item LTN constraint violation rate (should be $\approx 0$)
    \item Latency percentiles (p50, p95, p99, p99.9)
\end{itemize}

\newpage
% =============================================================================
% FUTURE DIRECTIONS
% =============================================================================
\section{Future Directions: Towards Quant 5.0}

\subsection{Quantum Computing Integration}

Quantum algorithms offer potential advantages for:

\begin{itemize}
    \item \textbf{Portfolio Optimization:} Quadratic Unconstrained Binary Optimization (QUBO) via quantum annealing
    \item \textbf{Option Pricing:} Quantum Monte Carlo with exponential speedup
    \item \textbf{Risk Analysis:} Quantum amplitude estimation for tail risk computation
\end{itemize}

JANUS is designed to integrate quantum co-processors via:
\begin{itemize}
    \item Modular risk engine interface (classical or quantum backend)
    \item Hybrid classical-quantum optimization loops
    \item Benchmarking quantum advantage on specific subproblems
\end{itemize}

\subsection{Continual Learning and Meta-Learning}

Current limitations:
\begin{itemize}
    \item Models are retrained periodically but not continuously
    \item Catastrophic forgetting when market regimes shift
    \item Slow adaptation to novel market conditions
\end{itemize}

Future enhancements:
\begin{itemize}
    \item \textbf{Elastic Weight Consolidation (EWC):} Protect important weights from updates
    \item \textbf{Meta-Learning (MAML):} Learn initialization that adapts quickly to new regimes
    \item \textbf{Lifelong Learning:} Incremental schema formation without full retraining
\end{itemize}

\subsection{Multi-Agent Cooperation and Competition}

Markets are inherently multi-agent. Future JANUS versions may include:

\begin{itemize}
    \item \textbf{Population-Based Training:} Multiple JANUS instances with diverse strategies
    \item \textbf{Cooperative Agents:} Agents share schemas via federated learning
    \item \textbf{Adversarial Agents:} Simulate market makers, informed traders, noise traders
    \item \textbf{Game-Theoretic Equilibria:} Nash equilibrium strategies in multi-agent auctions
\end{itemize}

\subsection{Regulatory AI and Automated Compliance}

Symbolic reasoning can be extended to:

\begin{itemize}
    \item \textbf{Automated Regulation Parsing:} Convert SEC rules to LTN predicates
    \item \textbf{Real-Time Compliance Monitoring:} Flag potential violations before execution
    \item \textbf{Regulatory Stress Testing:} Simulate proposed rule changes on strategy performance
\end{itemize}

\newpage
% =============================================================================
% CONCLUSION
% =============================================================================
\section{Conclusion: The Path Forward}

Project JANUS represents a synthesis of multiple frontiers in AI and computational finance:

\begin{itemize}
    \item \textbf{Computer Vision:} GAF transforms time series into images, unlocking CNNs and ViTs
    \item \textbf{Symbolic AI:} LTN embeds logical constraints as differentiable predicates
    \item \textbf{Neuroscience:} Neuromorphic architecture mirrors biological brain organization
    \item \textbf{Systems Engineering:} Rust-first implementation ensures safety and performance
    \item \textbf{Memory Systems:} Wake-sleep cycle separates real-time inference from reflective learning
\end{itemize}

The dual architecture—Forward for real-time trading, Backward for consolidation—mirrors the biological imperative of balancing immediate response with long-term adaptation. By decoupling these concerns, JANUS achieves both microsecond latencies and deep contemplative learning.

The neuromorphic mapping is not metaphorical. Each brain region corresponds to a specific computational challenge in autonomous trading:

\begin{itemize}
    \item Visual cortex detects patterns in transformed time series
    \item Prefrontal cortex enforces regulatory and risk constraints
    \item Hippocampus stores episodic experiences for replay
    \item Basal ganglia adjudicates action selection via dual pathways
    \item Cerebellum predicts execution outcomes
    \item Amygdala implements circuit breakers and risk alerts
\end{itemize}

This architecture is \textit{explainable by design}. Every decision generates an audit trail tracing:
\begin{enumerate}
    \item Which visual patterns were detected (Grad-CAM)
    \item Which logical constraints were evaluated (LTN trace)
    \item Which modalities were trusted (GCA gating)
    \item Why the action was authorized (Go/No-Go scores)
\end{enumerate}

This transparency is not incidental—it is the system's core value proposition. In an era of black box AI failures, JANUS offers a ``glass box'' alternative: a system that is both powerful and accountable.

\subsection{Companion Documents}

This main document provides the conceptual framework. Technical details are in:

\begin{enumerate}
    \item \textbf{janus\_forward.tex} — Algorithms for visual encoding, LTN reasoning, multimodal fusion, and decision-making in the Forward service

    \item \textbf{janus\_backward.tex} — Memory hierarchy, prioritized replay, SWR simulation, UMAP visualization, and vector database integration in the Backward service

    \item \textbf{janus\_neuromorphic\_architecture.tex} — Complete neuromorphic mapping, brain region implementations, information flow diagrams, and architectural invariants

    \item \textbf{janus\_rust\_implementation.tex} — Rust module structure, ML framework strategy, async service architecture, deployment pipelines, and implementation roadmap
\end{enumerate}

\subsection{Call to Action}

The transition from Quant 3.0 to Quant 4.0 is not merely an incremental improvement—it is a paradigm shift. The systems we build today will shape the financial markets of the next decade. JANUS offers a blueprint for autonomous trading systems that are:

\begin{itemize}
    \item \textbf{Powerful:} Leveraging state-of-the-art deep learning for pattern recognition
    \item \textbf{Safe:} Enforcing constraints through symbolic reasoning and fail-safe design
    \item \textbf{Transparent:} Generating auditable explanations for every decision
    \item \textbf{Adaptive:} Learning from experience through biologically-inspired memory systems
    \item \textbf{Scalable:} Implemented in Rust for production-grade performance and reliability
\end{itemize}

The future of quantitative finance will be shaped not by monolithic black boxes, but by hybrid systems that integrate the best of connectionist and symbolic AI, guided by the architectural principles discovered through millions of years of biological evolution.

JANUS is the first step on this path. The journey continues.

\vfill

\begin{center}
\textit{``The Roman god Janus is the god of transitions, passages, and new beginnings.}\\
\textit{Looking simultaneously to the past and the future,}\\
\textit{he embodies the duality required for true intelligence:}\\
\textit{learning from history while adapting to the unknown.''}
\end{center}

\newpage
% =============================================================================
% REFERENCES
% =============================================================================
\section*{References}

\begin{enumerate}[leftmargin=*]
    \item Wang, Z., \& Oates, T. (2015). \textit{Imaging time-series to improve classification and imputation}. Proceedings of IJCAI.

    \item Arnab, A., Dehghani, M., Heigold, G., Sun, C., Lučić, M., \& Schmid, C. (2021). \textit{ViViT: A Video Vision Transformer}. ICCV 2021.

    \item Badreddine, S., d'Avila Garcez, A., Serafini, L., \& Spranger, M. (2022). \textit{Logic Tensor Networks}. Artificial Intelligence, 303, 103649.

    \item Almgren, R., \& Chriss, N. (2001). \textit{Optimal execution of portfolio transactions}. Journal of Risk, 3, 5-40.

    \item Daw, N. D., Niv, Y., \& Dayan, P. (2005). \textit{Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control}. Nature Neuroscience, 8(12), 1704-1711.

    \item Buzsáki, G. (2015). \textit{Hippocampal sharp wave-ripple: A cognitive biomarker for episodic memory and planning}. Hippocampus, 25(10), 1073-1188.

    \item McClelland, J. L., McNaughton, B. L., \& O'Reilly, R. C. (1995). \textit{Why there are complementary learning systems in the hippocampus and neocortex}. Psychological Review, 102(3), 419.

    \item McInnes, L., Healy, J., \& Melville, J. (2018). \textit{UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}. arXiv:1802.03426.

    \item Easley, D., López de Prado, M. M., \& O'Hara, M. (2012). \textit{Flow toxicity and liquidity in a high-frequency world}. The Review of Financial Studies, 25(5), 1457-1493.

    \item Schaul, T., Quan, J., Antonoglou, I., \& Silver, D. (2015). \textit{Prioritized experience replay}. ICLR 2016.

    \item Veličković, P., Ying, R., Padovano, M., Hadsell, R., \& Blundell, C. (2019). \textit{Neural execution of graph algorithms}. ICLR 2020.

    \item Ansari, A. F., et al. (2024). \textit{Chronos: Learning the language of time series}. Amazon Science.

    \item Argyris, C., \& Schön, D. A. (1974). \textit{Theory in practice: Increasing professional effectiveness}. Jossey-Bass.
\end{enumerate}

\newpage
% =============================================================================
% APPENDIX
% =============================================================================
\section*{Appendix: Implementation Checklist}

\subsection*{Forward Service (Rust)}

\begin{itemize}
    \item[$\square$] GAF transformation module with learnable parameters
    \item[$\square$] GAF video generation with sliding windows
    \item[$\square$] ONNX Runtime integration for ViViT inference
    \item[$\square$] LTN predicate evaluation engine
    \item[$\square$] Lukasiewicz t-norm implementations
    \item[$\square$] Gated cross-attention fusion
    \item[$\square$] Basal ganglia dual pathways (Go/No-Go)
    \item[$\square$] Cerebellar forward model for slippage prediction
    \item[$\square$] Lock-free experience buffer writes
    \item[$\square$] gRPC API for order submission
    \item[$\square$] Async runtime (Tokio) for market data streams
    \item[$\square$] Circuit breaker implementations (amygdala)
    \item[$\square$] Audit logging (JSON structured logs)
    \item[$\square$] Prometheus metrics export
\end{itemize}

\subsection*{Backward Service (Rust)}

\begin{itemize}
    \item[$\square$] Prioritized replay buffer with SumTree
    \item[$\square$] SWR simulation with time compression
    \item[$\square$] Importance sampling correction
    \item[$\square$] Schema formation via clustering
    \item[$\square$] Recall-gated consolidation
    \item[$\square$] Qdrant client for vector database
    \item[$\square$] UMAP projection (ONNX or native)
    \item[$\square$] AlignedUMAP for multi-epoch analysis
    \item[$\square$] Parametric UMAP for real-time anomaly detection
    \item[$\square$] Rayon parallel batch processing
    \item[$\square$] Model export and versioning
    \item[$\square$] Schema pruning logic
\end{itemize}

\subsection*{Training Gateway (Python)}

\begin{itemize}
    \item[$\square$] PyTorch training loop
    \item[$\square$] FastAPI REST endpoints
    \item[$\square$] Celery task queue for async jobs
    \item[$\square$] ONNX export pipeline
    \item[$\square$] Model validation scripts
    \item[$\square$] Hyperparameter tuning (Optuna)
    \item[$\square$] Experiment tracking (MLflow or Weights \& Biases)
\end{itemize}

\subsection*{Infrastructure}

\begin{itemize}
    \item[$\square$] Docker Compose for local development
    \item[$\square$] Kubernetes manifests (Deployments, Services, ConfigMaps)
    \item[$\square$] Helm charts for versioned releases
    \item[$\square$] PostgreSQL for metadata
    \item[$\square$] Qdrant for vector storage
    \item[$\square$] Redis for pub/sub and caching
    \item[$\square$] Prometheus + Grafana monitoring
    \item[$\square$] CI/CD pipeline (GitHub Actions or GitLab CI)
    \item[$\square$] Shadow deployment workflow
    \item[$\square$] Automated backtesting on commit
\end{itemize}

\subsection*{Validation}

\begin{itemize}
    \item[$\square$] Unit tests (>80\% coverage)
    \item[$\square$] Integration tests (end-to-end flows)
    \item[$\square$] Synthetic market simulations
    \item[$\square$] Historical backtest suite
    \item[$\square$] Black swan stress tests
    \item[$\square$] Paper trading validation
    \item[$\square$] Latency profiling
    \item[$\square$] Reality gap analysis
\end{itemize}

\end{document}
